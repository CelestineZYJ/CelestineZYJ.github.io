<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Yuji Zhang, zhang yuji"> 
<meta name="description" content="Yuji Zhang's Homepage">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuji Zhang's Homepage</title>

</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1> Yuji Zhang (张雨季) </h1> 
				</div>

				<h3>Postdoc</h3>
				<p>
					University of Illinois at Urbana-Champaign <br>
					<br>
					<b>Email</b>: <tt>yujiz@illinois.edu</tt> 
					<br>
					<a href="https://scholar.google.com/citations?user=meTtEDcAAAAJ&hl=en"><img src="pic/google-scholar-96.png" height="25px" style="margin-bottom:-5px"> Google Scholar</a> 
					<a href="https://twitter.com/Yuji_Zhang_NLP"><img src="pic/twitter-90.png" height="25px" style="margin-bottom:-5px"> Twitter</a>
				
				</p>
			
			</td>
			<td>
				<img src="pic/yjzhang.jpg" id="potrait" width="300"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>


<p style="text-align:justify";>
	I am a postdoc researcher in the <a href="https://illinois.edu//" target="_blank">University of Illinois at Urbana-Champaign (UIUC)</a>.
	I am fortunately supervised by Prof. <a href="https://blender.cs.illinois.edu/hengji.html" target="_blank">Heng Ji </a> and Prof. <a href="https://czhai.cs.illinois.edu/" target="_blank">Chengxiang Zhai</a>. 
</p>


<h2>Research</h2>
<p style="text-align:justify";>
	I have broad interests in Natural Language Processing (NLP), theoretical interpretation of large language models (LLMs), and trustworthy LLMs. Especially, I focus on the following directions: 
	<ul>
	<li> how to effectively and efficiently acquire real-world knowledge to equip and update large language models in the temporally evolving world.
	</li>
	<li> I am recently focusing on interpreting why large language models hallucinate.
	</li>
	
	</ul>
</p>


<h2> Publications  
<h4>(see full list in <a href="https://scholar.google.com/citations?user=meTtEDcAAAAJ&hl=en">Google Scholar</a>)</h4>
</h2>

<p> 2020 - Present </p>
<ul>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>Atomic Reasoning for Scientific Table Claim Verification</h3> 
		<b>Yuji Zhang</b>, Qingyun Wang, Cheng Qian, Jiateng Liu, Chenkai Sun, Denghui Zhang, Tarek Abdelzaher, Chengxiang Zhai, Preslav Nakov, Heng Ji. <br>
		<i>Arxiv</i> <br>
		[<a href="https://arxiv.org/abs/2506.06972">Arxiv</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination*</h3> 
		<b>Yuji Zhang</b>, Sha Li, Cheng Qian, Jiateng Liu, Pengfei Yu, Yi R. Fung, Chi Han, Kathleen McKeown, Chengxiang Zhai, Manling Li, Heng Ji. <br>
		<i>ACL 2025</i> <br>
		[<a href="https://www.arxiv.org/abs/2502.16143">ACL 2025</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models*</h3> 
		<b>Yuji Zhang</b>, Sha Li, Jiateng Liu, Pengfei Yu, Yi R. Fung, Jing Li, Manling Li, Heng Ji. <br>
		<i>Arxiv preprint</i> <br>
		[<a href="https://arxiv.org/abs/2407.08039">Arxiv</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>Internal Activation as the Polar Star for Steering Unsafe LLM Behavior</h3> 
		Peixuan Han, Cheng Qian, Xiusi Chen,  <b>Yuji Zhang</b>, Denghui Zhang, Heng Ji. <br>
		<i>EMNLP 2025</i> <br>
		[<a href="https://arxiv.org/abs/2502.01042">EMNLP 2025</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>EscapeBench: Pushing Language Models to Think Outside the Box</h3> 
		Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, <b>Yuji Zhang</b>, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji. <br>
		<i>ACL 2025</i> <br>
		[<a href="https://arxiv.org/abs/2412.13549">ACL 2025</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation</h3> 
		Jiateng Liu*, Pengfei Yu*, <b>Yuji Zhang</b>, Sha Li, Zixuan Zhang, Heng Ji. <br>
		<i>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2024.</i> <br>
		[<a href="https://aclanthology.org/2024.emnlp-main.282/">EMNLP 2024</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>VIBE: Topic-Driven Temporal Adaptation for Twitter Classification</h3> 
		<b>Yuji Zhang</b>, Jing Li, Wenjie Li. <br>
		<i>Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023.</i> <br>
		[<a href="https://arxiv.org/abs/2310.10191">EMNLP 2023</a>]
	    </p>
    </li>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3>Towards Fair Financial Services for All: A Temporal GNN Approach for Individual Fairness on Transaction Networks</h3> 
		Zixing Song, <b>Yuji Zhang</b>, Irwin King. <br>
		<i>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management.</i> <br>
		[<a href="https://dl.acm.org/doi/abs/10.1145/3583780.3615091">CIKM '23</a>]
	    </p>
	<li> <p style="margin-left: 0px; line-height: 140%; margin-top: 10px; margin-bottom: 10px;">
		<h3># HowYouTagTweets: Learning User Hashtagging Preferences via Personalized Topic Attention</h3> 
		<b>Yuji Zhang</b>, Yubo Zhang, Chunpu Xu, Jing Li, Ziyan Jiang, Baolin Peng. <br>
		<i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021.</i> <br>
		[<a href="https://aclanthology.org/2021.emnlp-main.616/">EMNLP 2021</a>]
	    </p> 
</ul>

<h2>Recent News </h2>
<p style="margin-left: 0px; line-height: 120%; margin-top: 15px; margin-bottom: 15px;">
	<strong> Invited Talks, Tutorials, Workshops, and Sevice</strong> <br> 
</p>
	<ul style="list-style-type:none">
    		<li>[Aug 2025] Organized a Workshop on <span style="color:#4682B4;">"Towards Knowledgeable Foundation Models"</span> at <span style="color:#FF69B4;">ACL 2025</span></li>
			<li>[Aug 2025] Session chair for <span style="color:#4682B4;">"Language Models and Interpretability"</span> at <span style="color:#FF69B4;">ACL 2025</span></li>
			<li>[Aug 2025] Session chair for <span style="color:#4682B4;">"Language Modeling"</span> at <span style="color:#FF69B4;">ACL 2025</span></li>
    		<li>[Apr 2025] Invited Talk of <span style="color:#4682B4;">"The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination"</span> at <span style="color:#FF69B4;">Ploutos</span></li>
    		<li>[Apr 2025] Invited Talk of <span style="color:#4682B4;">"The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination"</span> at <span style="color:#FF69B4;">Chinese Academy of Sciences</span></li>
    		<li>[Mar 2025] Invited Talk of <span style="color:#4682B4;">"The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination"</span> at <span style="color:#FF69B4;">University of Texas at Austin</span></li>
    		<li>[Feb 2025] Organized a Tutorial on <span style="color:#4682B4;">"The Lifecycle of Knowledge in Large Language Models: Memorization, Editing, and Beyond"</span> at <span style="color:#FF69B4;">AAAI 2025</span></li>
    		<li>[Aug 2024] Invited Talk of <span style="color:#4682B4;">"Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models"</span> at <span style="color:#FF69B4;">Beijing Academy of Artificial Intelligence</span></li>
</ul>

<h2> Honors </h2>
<ul>
	<li> 
		Outstanding Student Leader of Southeast University 2017, 2018, 2019
	</li>
	<li> 
		Second Prize in National Undergraduate Mathematical Contest in Modeling, 2018
    </li>
	<li> 
		Skyworth Scholarship, 2018
	</li>
	<li> 
		National Scholarship (Top 1%, the highest scholarship for undergraduates), 2017
	</li>
	<li> 
		Merit Student of Jiangsu Province (Top 0.1%), 2016
	</li>
</ul>

	
<h2> Experiences </h2>
<ul>
	<li> 
		2020/01 - 2020/06: Research intern at <a href="https://home.dartmouth.edu/" target="_blank">Dartmouth College</a>
		(Advisors: Prof. <a href="https://www.cs.dartmouth.edu/~xingdong/" target="_blank">Xingdong Yang</a>, Prof. <a href="https://teyenwu.com/" target="_blank">Te-Yen Wu</a>)
	</li>
	<li> 
		2023/12 - 2024/08: Visiting PhD student at <a href="https://illinois.edu/">UIUC</a>
		(Advisor: Prof. <a href="https://blender.cs.illinois.edu/hengji.html" target="_blank">Heng Ji</a>)
    </li>
</ul>




<h2>Professional Activities </h2>
<p style="margin-left: 0px; line-height: 120%; margin-top: 15px; margin-bottom: 15px;">
	<strong> Instructor</strong> <br> 
</p>
	<ul style="list-style-type:none">
		<li>UIUC CS 591: Biologically Plausible Artificial Intelligence, Fall 2025, UIUC</li>
	</ul>
<p style="margin-left: 0px; line-height: 120%; margin-top: 15px; margin-bottom: 15px;">
	<strong> Instructor</strong> <br> 
</p>
	<ul style="list-style-type:none">
		<li>UIUC CS 591: Biologically Plausible Artificial Intelligence, Spring 2025, UIUC</li>
	</ul>
	
<p style="margin-left: 0px; line-height: 120%; margin-top: 15px; margin-bottom: 15px;">
	<strong> Teaching Assistant</strong> <br> 
</p>
	<ul style="list-style-type:none">
		<li>COMP 5511: Artificial Intelligence Concepts, Spring 2023, PolyU</li>
		<li>COMP 4141: Crowdfunding and e-Finance, Spring 2022, PolyU</li>
		<li>COMP 1433: Introduction to Data Analytics, Spring 2021, PolyU</li>
	</ul>
	
<p style="margin-left: 0px; line-height: 120%; margin-top: 15px; margin-bottom: 15px;">
    <strong>  Conference Reviewer </strong> <br> 
</p>
	<ul style="list-style-type:none">
		<li>ACL ARR (2025), KDD (2023), EMNLP (2024), EACL (2023), COLING (2023)</li>
	</ul>
  

<h2> Misc. </h2>
<ul>
    <li> <p>
		I enjoy reading and crafts. I have practiced taekwondo and piano for four years.  </p> 
	</li>
	<li> <p>
		In my free time, I love hiking, swimming, and exploring various cultural destinations.  </p> 
	</li>
</ul>


<div id="footer">
	<div id="footer-text"></div>
        <p><center>
      	<div id="clustrmaps-widget" style="width:10%">
		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=ZL37MJg_jJtcKBoIRaxajVLO3VArJoU1DWi6w2OgQWI"></script>
	</div>
	<p>
		<center>
        <br> 2020-2024 &copy; Yuji Zhang | Last updated: Dec. 2023
		</center>
	</p>		
</div>

</body>
</html>
